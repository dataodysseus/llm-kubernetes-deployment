{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jZLFqeQ4lWXzQdM-TE5ZNbIn7FV2l8nc","timestamp":1741224946423}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skqFueycSmFF","executionInfo":{"status":"ok","timestamp":1742151091774,"user_tz":240,"elapsed":15865,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"e5f9de35-390e-43c7-db0b-026e52b104c7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n","  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /tmp/pip-req-build-kc7af6hs\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-kc7af6hs\n","  Running command git checkout -q 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\n","  Resolved https://github.com/huggingface/transformers to commit 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n"]}]},{"cell_type":"code","source":["!pip install -q fastapi uvicorn pyngrok nest_asyncio transformers accelerate bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaonCPXL8fDS","executionInfo":{"status":"ok","timestamp":1742151167416,"user_tz":240,"elapsed":72724,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"2483ae80-99f7-48ee-a162-d6b0e7ebd596"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/94.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["# No quantization"],"metadata":{"id":"CsbFOz-WMcyw"}},{"cell_type":"code","source":["import uvicorn\n","from pyngrok import ngrok\n","import nest_asyncio\n","from fastapi import FastAPI, HTTPException\n","from pydantic import BaseModel\n","from transformers import AutoTokenizer, BitsAndBytesConfig, Gemma3ForCausalLM\n","import torch\n","\n","from google.colab import userdata\n","NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n","HUGGING_FACE_TOKEN = userdata.get('HF_TOKEN')\n","\n","# Allow nested event loops (required for Colab)\n","nest_asyncio.apply()\n","\n","app = FastAPI()\n","\n","quantization_config = BitsAndBytesConfig()\n","\n","# Define a request model for the prompt\n","class MessagesRequest(BaseModel):\n","    messages: list  # List of dictionaries with \"role\" and \"content\" keys\n","\n","# Load the model and tokenizer\n","MODEL_ID = \"google/gemma-3-1b-it\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HUGGING_FACE_TOKEN)\n","\n","model = Gemma3ForCausalLM.from_pretrained(\n","    MODEL_ID,\n","    quantization_config=quantization_config,\n","    token=HUGGING_FACE_TOKEN\n",").eval()\n","\n","@app.post(\"/generate\")\n","async def generate(request: MessagesRequest):\n","    try:\n","        # Tokenize the prompt\n","        inputs = tokenizer.apply_chat_template(\n","            request.messages,\n","            add_generation_prompt=True,\n","            tokenize=True,\n","            return_dict=True,\n","            return_tensors=\"pt\",\n","        ).to(model.device)\n","\n","        # Generate the response\n","        with torch.inference_mode():\n","          outputs = model.generate(**inputs, max_new_tokens=384)\n","\n","        # Decode the response\n","        response = tokenizer.batch_decode(outputs)\n","        return {\"response\": response}\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=str(e))\n","\n","# Set your ngrok authtoken\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","\n","# Start ngrok tunnel\n","public_url = ngrok.connect(8000).public_url\n","print(f\"Public URL: {public_url}\")\n","\n","# Run the app in the background\n","uvicorn.run(app, host=\"0.0.0.0\", port=8000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wiRMB-MdHaPI","outputId":"9fc375d7-bc23-4d7d-caa6-df97117ceeff","executionInfo":{"status":"ok","timestamp":1742157170131,"user_tz":240,"elapsed":111301,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:asyncio:Task exception was never retrieved\n","future: <Task finished name='Task-100' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 579, in run\n","    server.run()\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n","    return asyncio.run(self.serve(sockets=sockets))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n","    return loop.run_until_complete(task)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n","    self._run_once()\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n","    self.__step()\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n","    result = coro.send(None)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n","    with self.capture_signals():\n","  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n","    next(self.gen)\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n","    signal.raise_signal(captured_signal)\n","KeyboardInterrupt\n","`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"]},{"output_type":"stream","name":"stdout","text":["Public URL: https://1c13-34-58-179-37.ngrok-free.app\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [3369]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n","WARNING:pyngrok.process.ngrok:t=2025-03-16T20:31:11+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     34.74.190.211:0 - \"POST /generate HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [3369]\n"]}]}]}
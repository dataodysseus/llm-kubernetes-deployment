{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Z63fa24v98cA9RfoZsdI6gQHM6agS0lA","timestamp":1742443638450},{"file_id":"1jZLFqeQ4lWXzQdM-TE5ZNbIn7FV2l8nc","timestamp":1741224946423}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"59bcd1625b2649a9b692f8db122d68bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_799c5126bfcf46c7a67ab41f08c1819b","IPY_MODEL_64b2902b70ca4cc580b5ede52dcb3ece","IPY_MODEL_b799d708e2bd43809349d31125ef6359"],"layout":"IPY_MODEL_e268b5c5024049ed9fd490951ce4ee67"}},"799c5126bfcf46c7a67ab41f08c1819b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbc115dec0b141b7bd9a99521a1c0ffb","placeholder":"​","style":"IPY_MODEL_5caf317074744ee39087e325997be8e0","value":"Loading checkpoint shards: 100%"}},"64b2902b70ca4cc580b5ede52dcb3ece":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fb48c354adf4e4f83ccfb69a0b11d69","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_519a19feacb241bf9832c7dd2b43c30d","value":7}},"b799d708e2bd43809349d31125ef6359":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0649ec1b4c4d44dda58245962a5bb2af","placeholder":"​","style":"IPY_MODEL_66c512f335c949469b6692b980509435","value":" 7/7 [00:08&lt;00:00,  1.09s/it]"}},"e268b5c5024049ed9fd490951ce4ee67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc115dec0b141b7bd9a99521a1c0ffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5caf317074744ee39087e325997be8e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fb48c354adf4e4f83ccfb69a0b11d69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"519a19feacb241bf9832c7dd2b43c30d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0649ec1b4c4d44dda58245962a5bb2af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66c512f335c949469b6692b980509435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install -q transformers datasets accelerate bitsandbytes google-cloud-storage gguf langchain_community fastapi uvicorn pyngrok nest_asyncio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQXfJn6ZLzH8","executionInfo":{"status":"ok","timestamp":1744568836506,"user_tz":-360,"elapsed":80441,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"15793940-b524-4c76-d1ce-c4500026ace1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","from google.cloud import storage\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2. Set environment variable for credentials\n","credentials_path = \"/content/drive/MyDrive/gcp-key.json\"  # Path to your key file\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n","\n","# 3. Initialize GCS client\n","storage_client = storage.Client()\n","bucket_name = \"llm-test-bucket-2025\"  # Replace with your bucket name\n","bucket = storage_client.bucket(bucket_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSQPNmzjMRwW","executionInfo":{"status":"ok","timestamp":1744568923946,"user_tz":-360,"elapsed":41375,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"e0f64a4b-5169-4177-b100-5e84731dfbe8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 4. Save tokenizer and model to a local directory\n","model_dir = \"model_weights\"  # A local directory to save the model and tokenizer\n","os.makedirs(model_dir, exist_ok=True)"],"metadata":{"id":"49uEY1sUMffQ","executionInfo":{"status":"ok","timestamp":1744568934077,"user_tz":-360,"elapsed":5,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Define local directory where model files will be downloaded\n","def download_from_gcs(gcs_prefix, local_dir):\n","    \"\"\"Download all files from GCS folder to local directory.\"\"\"\n","    blobs = bucket.list_blobs(prefix=gcs_prefix)\n","    for blob in blobs:\n","        local_filepath = os.path.join(local_dir, os.path.basename(blob.name))\n","        print(f\"Downloading {blob.name} to {local_filepath}...\")\n","        blob.download_to_filename(local_filepath)\n","\n","# Download model weights from GCS\n","download_from_gcs(\"DeepSeek_R1_Distill_Qwen_7B\", model_dir)\n","\n","print(\"Model files downloaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gdO507QMinU","executionInfo":{"status":"ok","timestamp":1744570830770,"user_tz":-360,"elapsed":1847691,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"b600b5db-c545-4436-d4b4-ea4273ad0dfa"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading DeepSeek_R1_Distill_Qwen_7B/config.json to model_weights/config.json...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/generation_config.json to model_weights/generation_config.json...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00001-of-00007.safetensors to model_weights/model-00001-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00002-of-00007.safetensors to model_weights/model-00002-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00003-of-00007.safetensors to model_weights/model-00003-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00004-of-00007.safetensors to model_weights/model-00004-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00005-of-00007.safetensors to model_weights/model-00005-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00006-of-00007.safetensors to model_weights/model-00006-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model-00007-of-00007.safetensors to model_weights/model-00007-of-00007.safetensors...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/model.safetensors.index.json to model_weights/model.safetensors.index.json...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/special_tokens_map.json to model_weights/special_tokens_map.json...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/tokenizer.json to model_weights/tokenizer.json...\n","Downloading DeepSeek_R1_Distill_Qwen_7B/tokenizer_config.json to model_weights/tokenizer_config.json...\n","Model files downloaded successfully!\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Define paths\n","model_path = model_dir  # Path to downloaded model files\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Load model (ensure it uses 8-bit quantization)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_path,\n","    torch_dtype=torch.float16,  # Use float16 for efficiency\n","    device_map=\"auto\"  # Automatically map to available GPU\n",")\n","\n","print(\"Model loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["59bcd1625b2649a9b692f8db122d68bc","799c5126bfcf46c7a67ab41f08c1819b","64b2902b70ca4cc580b5ede52dcb3ece","b799d708e2bd43809349d31125ef6359","e268b5c5024049ed9fd490951ce4ee67","fbc115dec0b141b7bd9a99521a1c0ffb","5caf317074744ee39087e325997be8e0","1fb48c354adf4e4f83ccfb69a0b11d69","519a19feacb241bf9832c7dd2b43c30d","0649ec1b4c4d44dda58245962a5bb2af","66c512f335c949469b6692b980509435"]},"id":"8JNk9hTdNDXa","executionInfo":{"status":"ok","timestamp":1744570850464,"user_tz":-360,"elapsed":13302,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"64a5889b-5d24-4797-e112-cbc0eef10de5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59bcd1625b2649a9b692f8db122d68bc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["import uvicorn\n","from pyngrok import ngrok\n","import nest_asyncio\n","from fastapi import FastAPI, HTTPException\n","from pydantic import BaseModel\n","\n","from google.colab import userdata\n","NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n","HUGGING_FACE_TOKEN = userdata.get('HF_TOKEN')\n","\n","# Allow nested event loops (required for Colab)\n","nest_asyncio.apply()\n","\n","app = FastAPI()\n","\n","# Define a request model for the prompt\n","class MessagesRequest(BaseModel):\n","    messages: list  # List of dictionaries with \"role\" and \"content\" keys\n","\n","@app.post(\"/generate\")\n","async def generate(request: MessagesRequest):\n","    try:\n","        # Format the messages using the tokenizer's chat template\n","        prompt = tokenizer.apply_chat_template(request.messages, tokenize=False, add_generation_prompt=True)\n","\n","        # Tokenize the prompt\n","        inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n","\n","        # Generate the response\n","        generated_ids = model.generate(\n","            inputs.input_ids,\n","            max_new_tokens=5000,  # Adjust as needed\n","            temperature=0.7,      # Lower values make the output more deterministic\n","            top_k=50,             # Lower k focuses on higher probability tokens\n","            top_p=0.95,           # Lower values make the output more focused\n","            do_sample=True        # Enable sampling\n","        )\n","\n","        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)]\n","\n","        # response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","\n","        # Extract only the assistant's response (remove the prompt)\n","        # assistant_response = response.split(prompt)[-1].strip()\n","\n","        return {\"response\": response}\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=str(e))\n","\n","# Set your ngrok authtoken\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","\n","# Start ngrok tunnel\n","public_url = ngrok.connect(8000).public_url\n","print(f\"Public URL: {public_url}\")\n","\n","# Run the app in the background\n","uvicorn.run(app, host=\"0.0.0.0\", port=8000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhK6Uz6cNGhG","outputId":"c22cf398-03a9-4da7-c797-79c3b520736c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [956]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["Public URL: https://a373-34-143-160-92.ngrok-free.app\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     34.75.74.176:0 - \"POST /generate HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     34.75.74.176:0 - \"POST /generate HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     34.75.74.176:0 - \"POST /generate HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     34.75.74.176:0 - \"POST /generate HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     34.75.74.176:0 - \"POST /generate HTTP/1.1\" 200 OK\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1yRkG3-QT-u2_0J5LVNvNg_JTs7A1vzJW","timestamp":1742523807284}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d10352560fcc4626898dab7fcb18b369":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13beaaf27f1542a89a1085088aa9a5e6","IPY_MODEL_a76936f71e044fbdb81b6d94a9bdbfd1","IPY_MODEL_95e10ad7df1749cface81f12b4a71203"],"layout":"IPY_MODEL_37d57676758049358a8b97fb5ee79e89"}},"13beaaf27f1542a89a1085088aa9a5e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c05edf7cfce4878aae80e11b80b0cc8","placeholder":"​","style":"IPY_MODEL_bf9ab524c0f14ca8ada42797718e0eba","value":"Loading checkpoint shards: 100%"}},"a76936f71e044fbdb81b6d94a9bdbfd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a114efdfc8f4838b3ea8aa637b6dc3d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_961c963548eb4abdaa0485e89fc929ff","value":2}},"95e10ad7df1749cface81f12b4a71203":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8082d92429674844ae16d5a24d767169","placeholder":"​","style":"IPY_MODEL_db46487438ec41da8243cfccd8247f72","value":" 2/2 [00:02&lt;00:00,  1.21s/it]"}},"37d57676758049358a8b97fb5ee79e89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c05edf7cfce4878aae80e11b80b0cc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9ab524c0f14ca8ada42797718e0eba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a114efdfc8f4838b3ea8aa637b6dc3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"961c963548eb4abdaa0485e89fc929ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8082d92429674844ae16d5a24d767169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db46487438ec41da8243cfccd8247f72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install -q transformers datasets accelerate bitsandbytes google-cloud-storage gguf langchain_community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tV74yYIMxzJ3","outputId":"a101f243-dea3-4db2-8bc0-e82ff88f682a","executionInfo":{"status":"ok","timestamp":1742776354196,"user_tz":240,"elapsed":84033,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","from google.cloud import storage\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2. Set environment variable for credentials\n","credentials_path = \"/content/drive/MyDrive/gcp-key.json\"  # Path to your key file\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n","\n","# 3. Initialize GCS client\n","storage_client = storage.Client()\n","bucket_name = \"llm-test-bucket-2025\"  # Replace with your bucket name\n","bucket = storage_client.bucket(bucket_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dDjvbZs5Qoh","outputId":"af36a828-b1c5-4652-87e9-16eb22703371","executionInfo":{"status":"ok","timestamp":1742776714955,"user_tz":240,"elapsed":36324,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 4. Save tokenizer and model to a local directory\n","model_dir = \"model_weights_4bit\"  # A local directory to save the model and tokenizer\n","os.makedirs(model_dir, exist_ok=True)"],"metadata":{"id":"uQh52RhkqArc","executionInfo":{"status":"ok","timestamp":1742776951328,"user_tz":240,"elapsed":12,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Define local directory where model files will be downloaded\n","def download_from_gcs(gcs_prefix, local_dir):\n","    \"\"\"Download all files from GCS folder to local directory.\"\"\"\n","    blobs = bucket.list_blobs(prefix=gcs_prefix)\n","    for blob in blobs:\n","        local_filepath = os.path.join(local_dir, os.path.basename(blob.name))\n","        print(f\"Downloading {blob.name} to {local_filepath}...\")\n","        blob.download_to_filename(local_filepath)\n","\n","# Download model weights from GCS\n","download_from_gcs(\"model_weights\", model_dir)\n","\n","print(\"Model files downloaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qOg_pma_q8un","executionInfo":{"status":"ok","timestamp":1742777329778,"user_tz":240,"elapsed":371840,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"af156296-53f9-4c8b-c54e-e12c9fcb8e24"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading model_weights/config.json to model_weights_4bit/config.json...\n","Downloading model_weights/generation_config.json to model_weights_4bit/generation_config.json...\n","Downloading model_weights/model-00001-of-00002.safetensors to model_weights_4bit/model-00001-of-00002.safetensors...\n","Downloading model_weights/model-00002-of-00002.safetensors to model_weights_4bit/model-00002-of-00002.safetensors...\n","Downloading model_weights/model.safetensors.index.json to model_weights_4bit/model.safetensors.index.json...\n","Downloading model_weights/special_tokens_map.json to model_weights_4bit/special_tokens_map.json...\n","Downloading model_weights/tokenizer.json to model_weights_4bit/tokenizer.json...\n","Downloading model_weights/tokenizer_config.json to model_weights_4bit/tokenizer_config.json...\n","Model files downloaded successfully!\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Define paths\n","model_path = model_dir  # Path to downloaded model files\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Load model (ensure it uses 8-bit quantization)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_path,\n","    torch_dtype=torch.float16,  # Use float16 for efficiency\n","    device_map=\"auto\"  # Automatically map to available GPU\n",")\n","\n","print(\"Model loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["d10352560fcc4626898dab7fcb18b369","13beaaf27f1542a89a1085088aa9a5e6","a76936f71e044fbdb81b6d94a9bdbfd1","95e10ad7df1749cface81f12b4a71203","37d57676758049358a8b97fb5ee79e89","6c05edf7cfce4878aae80e11b80b0cc8","bf9ab524c0f14ca8ada42797718e0eba","9a114efdfc8f4838b3ea8aa637b6dc3d","961c963548eb4abdaa0485e89fc929ff","8082d92429674844ae16d5a24d767169","db46487438ec41da8243cfccd8247f72"]},"id":"Rggig3NPq8ql","executionInfo":{"status":"ok","timestamp":1742777353623,"user_tz":240,"elapsed":8593,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"ff893ad7-b3d3-44eb-ceec-d54c89931f75"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10352560fcc4626898dab7fcb18b369"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","import torch\n","from langchain import PromptTemplate, LLMChain\n","from langchain.llms import HuggingFacePipeline\n","import markdown\n","\n","def generate_response(prompt, model, tokenizer):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","    outputs = model.generate(**inputs, max_new_tokens=5000)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    # Remove everything before and including '</think>'\n","    if \"</think>\" in response:\n","        response = response.split(\"</think>\")[-1].strip()\n","\n","    return response\n","\n","# Create the text-generation pipeline\n","text_generation_pipeline = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    max_new_tokens=5000,\n","    temperature=0.9,\n","    do_sample=True\n",")\n","\n","# Create a HuggingFacePipeline\n","llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n","\n","# Define a simple prompt template\n","template = \"\"\"Question: {question}\n","\n","Answer:\"\"\"\n","prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n","\n","# Create the LLMChain\n","llm_chain = LLMChain(prompt=prompt, llm=llm)\n","\n","# Run the chain and clean output\n","question = '''\n","          Given a 2d matrix cost[][] of size n where cost[i][j] denotes the cost of moving from city i to city j.\n","          The task is to complete a tour from city 0 (0-based index) to all other cities such that we visit each city\n","          exactly once and then at the end come back to city 0 at minimum cost. Note the difference between Hamiltonian Cycle and TSP. T\n","          he Hamiltonian cycle problem is to find if there exists a tour that visits every city exactly once.\n","          Here we know that Hamiltonian Tour exists (because the graph is complete) and in fact, many such tours exist,\n","          the problem is to find a minimum weight Hamiltonian Cycle.\n","          Example:\n","          Input: cost[][] = [[0, 111], [112, 0]]\n","          Output: 223\n","          Explanation: We can visit 0->1->0 and cost = 111 + 112 = 223.\n","          Considering above: what is the minimum cost where cost[][] = [[0, 1000, 5000], [5000, 0, 1000], [1000, 5000, 0]], hint: the cost should be less thant 5000?\n","          '''\n","response = llm_chain.run(question).strip()\n","\n","# Remove echoes of the question if present in response\n","if question in response:\n","    response = response.replace(question, \"\").strip()\n","\n","# Remove everything before and including '</think>'\n","if \"</think>\" in response:\n","    response = response.split(\"</think>\")[-1].strip()\n","\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rw2D7WtWq8m9","executionInfo":{"status":"ok","timestamp":1742777621257,"user_tz":240,"elapsed":258950,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"a09613ae-5b61-474a-b73f-41442565a13c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","<ipython-input-6-dd58b8e13b31>:29: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n","  llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n","<ipython-input-6-dd58b8e13b31>:38: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n","  llm_chain = LLMChain(prompt=prompt, llm=llm)\n","<ipython-input-6-dd58b8e13b31>:54: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  response = llm_chain.run(question).strip()\n","/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Given a cost matrix \\( \\text{cost[][]} \\) of size \\( n \\) where \\( \\text{cost}[i][j] \\) denotes the cost of moving from city \\( i \\) to city \\( j \\), the task is to find a Hamiltonian cycle that visits each city exactly once and returns to the starting city (city 0) at minimum cost.\n","\n","The cost matrix provided is:\n","\\[\n","\\begin{bmatrix}\n","0 & 1000 & 5000 \\\\\n","5000 & 0 & 1000 \\\\\n","1000 & 5000 & 0\n","\\end{bmatrix}\n","\\]\n","\n","The goal is to find the Hamiltonian cycle that starts and ends at city 0, visiting all other cities exactly once, with the minimum total cost.\n","\n","Key steps:\n","1. Identify the possible Hamiltonian cycles.\n","2. Calculate the cost for each cycle.\n","3. Select the cycle with the minimum cost.\n","\n","Possible cycles:\n","- \\( 0 \\rightarrow 1 \\rightarrow 2 \\rightarrow 0 \\)\n","- \\( 0 \\rightarrow 2 \\rightarrow 1 \\rightarrow 0 \\)\n","\n","Calculating the cost for each cycle:\n","- Cycle \\( 0 \\rightarrow 1 \\rightarrow 2 \\rightarrow 0 \\):\n","  - \\( 0 \\rightarrow 1 \\) cost: 1000\n","  - \\( 1 \\rightarrow 2 \\) cost: 1000\n","  - \\( 2 \\rightarrow 0 \\) cost: 1000\n","  - Total\n"]}]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","prompt = \"Can you provide me with a 5 day trip plan for a trip to France?\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": prompt}\n","]\n","\n","text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n","generated_ids = model.generate(model_inputs.input_ids,max_new_tokens=5000)\n","generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRFhdp3Mq8Yl","executionInfo":{"status":"ok","timestamp":1742778325525,"user_tz":240,"elapsed":63696,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"78aa59ee-eee2-472d-a502-062ac23a52b6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]}]},{"cell_type":"code","source":["response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHUsZvyY7VmS","executionInfo":{"status":"ok","timestamp":1742778336625,"user_tz":240,"elapsed":30,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"5729b8bd-6872-4237-b6a2-b0da2b489da6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Okay, so I'm planning a 5-day trip to France, and I need to figure out a good itinerary. I've never been before, so I need to make sure I see the main attractions without feeling rushed. Let me think about what I know about France.\n","\n","First, I know Paris is the capital, so that should definitely be the first day. I've heard the Eiffel Tower, the Louvre, and maybe the Sacré-Cœur. On the first day, I can arrive, maybe drop my bags off, and then explore those iconic spots. Maybe in the morning, visit the Eiffel Tower, then the Louvre in the afternoon. Evening could be a nice dinner and a stroll along the Seine. I think that's a solid first day.\n","\n","On the second day, I want to explore more of Paris. Maybe visit some museums like the Musée d'Orsay or the Pompidou. I've heard the Pompidou is modern and has a great view from the roof. Maybe in the morning, go to the Musée d'Orsay, then in the afternoon visit the Pompidou, and end the day with a nice dinner and a cabaret show. That sounds fun.\n","\n","Third day, maybe take a day trip. Versailles is close to Paris, so I can go there. Explore the palace, the gardens, and maybe the Grand Palace and the Hall of Mirrors. In the evening, maybe visit a nearby town like Fontainebleau or something. I'm not sure about Fontainebleau, but it's a historical town. Alternatively, maybe a vineyard visit if I have time.\n","\n","Fourth day, I should probably head to another city. I've heard Lyon is a gastronomic city. So maybe take a train to Lyon. In Lyon, I can visit the basilica, walk around the old town, and have a nice meal. Maybe spend the afternoon there and then return to Paris for the last evening.\n","\n","Fifth day, departure. Maybe on the way back, stop at Disneyland or another nearby attraction if time permits. But if not, just head to the airport.\n","\n","Wait, but I need to check the distances and travel times between these places. Versailles is only about 30 minutes by train from Paris, so that's doable. Lyon is about an hour and a half away. Is there enough time to visit Versailles in a day? Maybe in the morning, visit the palace, then spend the afternoon in Fontainebleau or another nearby town. Then head back to Paris for dinner and a last-minute stroll.\n","\n","Also, I should think about meal times. France has a lot of great food, so I need to plan meals into the itinerary. Maybe include a market visit or a Michelin star restaurant if possible.\n","\n","Transportation-wise, trains are convenient between cities, so I can use that. Need to figure out the exact times and booking tickets in advance.\n","\n","I should also consider the weather. Maybe pack accordingly, as May or June could have varying weather.\n","\n","Hmm, maybe on the second day, after the museums, take a river cruise on the Seine. That could be a nice way to see the city from the water. Or maybe just a walking tour of Montmartre in the evening.\n","\n","Wait, I have to make sure I'm not overpacking each day. Each day should have a balance of sightseeing and relaxation.\n","\n","I think I've got a rough plan. Now, let me structure it properly, making sure each day flows well without too much traveling. Maybe start with Paris, then a day trip, then another city, then back to Paris, and finally depart.\n","\n","I think that's a good structure. Now, I can write this out as a 5-day plan with each day's activities, including where to stay, meals, and key attractions.\n","</think>\n","\n","Here's a well-organized and balanced 5-day trip plan for France, ensuring a mix of sightseeing, culture, and relaxation:\n","\n","### Day 1: Arrival in Paris\n","- **Morning:** Arrive in Paris, check into your accommodation.\n","- **Afternoon:** Visit the Eiffel Tower and explore the surrounding area. Stroll along the Champ de Mars.\n","- **Evening:** Enjoy a picnic with a view from a rooftop or a romantic dinner by the Seine.\n","- **Night:** Overnight stay in Paris.\n","\n","### Day 2: Explore Parisian Museums\n","- **Morning:** Visit the Louvre Museum.\n","- **Afternoon:** Explore the Musée d'Orsay or the Pompidou Museum, then enjoy a riverside café.\n","- **Evening:** Take a sunset river cruise on the Seine.\n","- **Night:** Experience a traditional cabaret show.\n","- **Stay:** Overnight in Paris.\n","\n","### Day 3: Day Trip to Versailles\n","- **Morning:** Take a train to Versailles, visit the Palace and the Hall of Mirrors.\n","- **Afternoon:** Explore the gardens, Grand Park, and maybe the Petit Appartement.\n","- **Evening:** Dine at a local restaurant in Versailles or Fontainebleau.\n","- **Night:** Return to Paris for a relaxing evening.\n","- **Stay:** Overnight in Paris.\n","\n","### Day 4: Day Trip to Lyon\n","- **Morning:** Take a high-speed train to Lyon.\n","- **Afternoon:** Visit the Basilica of Notre-Dame and explore the old town.\n","- **Evening:** Enjoy a meal at a Michelin-starred restaurant and stroll along the Rhône.\n","- **Night:** Return to Paris.\n","- **Stay:** Overnight in Paris.\n","\n","### Day 5: Departure\n","- **Morning:** If time permits, visit Disneyland Paris or another attraction.\n","- **Afternoon:** Return to Paris for a last-minute shopping or café visit.\n","- **Evening:** Depart from Paris.\n","\n","This itinerary balances cultural immersion, historical exploration, and relaxation, ensuring a memorable trip through France. Adjustments can be made based on personal preferences and travel pace.\n"]}]},{"cell_type":"code","source":["# Remove echoes of the question if present in response\n","if question in response:\n","    response = response.replace(question, \"\").strip()\n","\n","# Remove everything before and including '</think>'\n","if \"</think>\" in response:\n","    response = response.split(\"</think>\")[-1].strip()\n","# Remove echoes of the question if present in response\n","if question in response:\n","    response = response.replace(question, \"\").strip()\n","\n","# Remove everything before and including '</think>'\n","if \"</think>\" in response:\n","    response = response.split(\"</think>\")[-1].strip()\n","\n","# print(response)\n","markdown_response = markdown.markdown(response)\n","print(markdown_response)"],"metadata":{"id":"B3uJZLyh8MPn","executionInfo":{"status":"ok","timestamp":1742778349337,"user_tz":240,"elapsed":23,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"8734b4d8-deb8-4b68-d5a3-929f1ad7c941","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["<p>Here's a well-organized and balanced 5-day trip plan for France, ensuring a mix of sightseeing, culture, and relaxation:</p>\n","<h3>Day 1: Arrival in Paris</h3>\n","<ul>\n","<li><strong>Morning:</strong> Arrive in Paris, check into your accommodation.</li>\n","<li><strong>Afternoon:</strong> Visit the Eiffel Tower and explore the surrounding area. Stroll along the Champ de Mars.</li>\n","<li><strong>Evening:</strong> Enjoy a picnic with a view from a rooftop or a romantic dinner by the Seine.</li>\n","<li><strong>Night:</strong> Overnight stay in Paris.</li>\n","</ul>\n","<h3>Day 2: Explore Parisian Museums</h3>\n","<ul>\n","<li><strong>Morning:</strong> Visit the Louvre Museum.</li>\n","<li><strong>Afternoon:</strong> Explore the Musée d'Orsay or the Pompidou Museum, then enjoy a riverside café.</li>\n","<li><strong>Evening:</strong> Take a sunset river cruise on the Seine.</li>\n","<li><strong>Night:</strong> Experience a traditional cabaret show.</li>\n","<li><strong>Stay:</strong> Overnight in Paris.</li>\n","</ul>\n","<h3>Day 3: Day Trip to Versailles</h3>\n","<ul>\n","<li><strong>Morning:</strong> Take a train to Versailles, visit the Palace and the Hall of Mirrors.</li>\n","<li><strong>Afternoon:</strong> Explore the gardens, Grand Park, and maybe the Petit Appartement.</li>\n","<li><strong>Evening:</strong> Dine at a local restaurant in Versailles or Fontainebleau.</li>\n","<li><strong>Night:</strong> Return to Paris for a relaxing evening.</li>\n","<li><strong>Stay:</strong> Overnight in Paris.</li>\n","</ul>\n","<h3>Day 4: Day Trip to Lyon</h3>\n","<ul>\n","<li><strong>Morning:</strong> Take a high-speed train to Lyon.</li>\n","<li><strong>Afternoon:</strong> Visit the Basilica of Notre-Dame and explore the old town.</li>\n","<li><strong>Evening:</strong> Enjoy a meal at a Michelin-starred restaurant and stroll along the Rhône.</li>\n","<li><strong>Night:</strong> Return to Paris.</li>\n","<li><strong>Stay:</strong> Overnight in Paris.</li>\n","</ul>\n","<h3>Day 5: Departure</h3>\n","<ul>\n","<li><strong>Morning:</strong> If time permits, visit Disneyland Paris or another attraction.</li>\n","<li><strong>Afternoon:</strong> Return to Paris for a last-minute shopping or café visit.</li>\n","<li><strong>Evening:</strong> Depart from Paris.</li>\n","</ul>\n","<p>This itinerary balances cultural immersion, historical exploration, and relaxation, ensuring a memorable trip through France. Adjustments can be made based on personal preferences and travel pace.</p>\n"]}]},{"cell_type":"code","source":["from IPython.display import HTML, display\n","display(HTML(markdown_response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"_EvAB5Ijqag8","executionInfo":{"status":"ok","timestamp":1742778361923,"user_tz":240,"elapsed":19,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"177805e3-482e-4154-a864-afaf4971702e"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<p>Here's a well-organized and balanced 5-day trip plan for France, ensuring a mix of sightseeing, culture, and relaxation:</p>\n","<h3>Day 1: Arrival in Paris</h3>\n","<ul>\n","<li><strong>Morning:</strong> Arrive in Paris, check into your accommodation.</li>\n","<li><strong>Afternoon:</strong> Visit the Eiffel Tower and explore the surrounding area. Stroll along the Champ de Mars.</li>\n","<li><strong>Evening:</strong> Enjoy a picnic with a view from a rooftop or a romantic dinner by the Seine.</li>\n","<li><strong>Night:</strong> Overnight stay in Paris.</li>\n","</ul>\n","<h3>Day 2: Explore Parisian Museums</h3>\n","<ul>\n","<li><strong>Morning:</strong> Visit the Louvre Museum.</li>\n","<li><strong>Afternoon:</strong> Explore the Musée d'Orsay or the Pompidou Museum, then enjoy a riverside café.</li>\n","<li><strong>Evening:</strong> Take a sunset river cruise on the Seine.</li>\n","<li><strong>Night:</strong> Experience a traditional cabaret show.</li>\n","<li><strong>Stay:</strong> Overnight in Paris.</li>\n","</ul>\n","<h3>Day 3: Day Trip to Versailles</h3>\n","<ul>\n","<li><strong>Morning:</strong> Take a train to Versailles, visit the Palace and the Hall of Mirrors.</li>\n","<li><strong>Afternoon:</strong> Explore the gardens, Grand Park, and maybe the Petit Appartement.</li>\n","<li><strong>Evening:</strong> Dine at a local restaurant in Versailles or Fontainebleau.</li>\n","<li><strong>Night:</strong> Return to Paris for a relaxing evening.</li>\n","<li><strong>Stay:</strong> Overnight in Paris.</li>\n","</ul>\n","<h3>Day 4: Day Trip to Lyon</h3>\n","<ul>\n","<li><strong>Morning:</strong> Take a high-speed train to Lyon.</li>\n","<li><strong>Afternoon:</strong> Visit the Basilica of Notre-Dame and explore the old town.</li>\n","<li><strong>Evening:</strong> Enjoy a meal at a Michelin-starred restaurant and stroll along the Rhône.</li>\n","<li><strong>Night:</strong> Return to Paris.</li>\n","<li><strong>Stay:</strong> Overnight in Paris.</li>\n","</ul>\n","<h3>Day 5: Departure</h3>\n","<ul>\n","<li><strong>Morning:</strong> If time permits, visit Disneyland Paris or another attraction.</li>\n","<li><strong>Afternoon:</strong> Return to Paris for a last-minute shopping or café visit.</li>\n","<li><strong>Evening:</strong> Depart from Paris.</li>\n","</ul>\n","<p>This itinerary balances cultural immersion, historical exploration, and relaxation, ensuring a memorable trip through France. Adjustments can be made based on personal preferences and travel pace.</p>"]},"metadata":{}}]},{"cell_type":"code","source":["!pip install gcsfs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2hku7Ixsrp_","executionInfo":{"status":"ok","timestamp":1742778586596,"user_tz":240,"elapsed":2822,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"f4ed1abf-05ec-433e-eccd-b8ea5490a43e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (3.11.14)\n","Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (4.4.2)\n","Collecting fsspec==2025.3.0 (from gcsfs)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs) (1.2.1)\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.19.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.32.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.18.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n","Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.24.2)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.4.3)\n","Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (1.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (2025.1.31)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.69.2)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (5.29.3)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.26.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n","Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fsspec\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.12.0\n","    Uninstalling fsspec-2024.12.0:\n","      Successfully uninstalled fsspec-2024.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datasets 3.4.1 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fsspec-2025.3.0\n"]}]},{"cell_type":"code","source":["import gcsfs\n","\n","# Initialize GCS file system\n","fs = gcsfs.GCSFileSystem(project=\"genai-model-dev-deploy\", token=credentials_path)\n","\n","# Define your bucket path\n","bucket_name = \"llm-test-bucket-2025\"\n","bucket_path = f\"gs://{bucket_name}/\"\n","\n","# Verify the bucket content\n","files = fs.ls(bucket_path)\n","print(\"Files in GCS bucket:\", files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqdpACEMszAF","executionInfo":{"status":"ok","timestamp":1742778773329,"user_tz":240,"elapsed":2326,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"d8d4b1be-8c95-4d65-f36e-823767941963"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Files in GCS bucket: ['llm-test-bucket-2025/model_weights']\n"]}]},{"cell_type":"code","source":["file_path = f\"{bucket_path}model_weights/tokenizer.json\"\n","\n","with fs.open(file_path, \"r\") as f:\n","    content = f.read()\n","    print(\"File content:\", content[:100])  # Print first 500 characters"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FK8JzK7Utomc","executionInfo":{"status":"ok","timestamp":1742778915308,"user_tz":240,"elapsed":4599,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"94b47967-104c-4137-ab27-e7b0365fb314"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["File content: {\n","  \"version\": \"1.0\",\n","  \"truncation\": null,\n","  \"padding\": null,\n","  \"added_tokens\": [\n","    {\n","      \"id\":\n"]}]},{"cell_type":"code","source":["import gcsfs\n","import os\n","\n","# Set up GCS authentication using service account\n","gcs_key_path = \"/content/drive/MyDrive/gcp-key.json\"\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = gcs_key_path\n","\n","# Initialize gcsfs\n","fs = gcsfs.GCSFileSystem(project=\"genai-model-dev-deploy\", token=gcs_key_path)\n","\n","# Define paths\n","bucket_name = \"llm-test-bucket-2025\"\n","gcs_model_path = f\"gs://{bucket_name}/model_weights\"\n","local_model_dir = \"deepseek_model_4b\"\n","os.makedirs(local_model_dir, exist_ok=True)\n","\n","# Download all model files from GCS\n","def download_from_gcs(gcs_path, local_dir):\n","    \"\"\"Download all files from a GCS directory to a local directory.\"\"\"\n","    blobs = fs.ls(gcs_path)\n","    for blob in blobs:\n","        local_filepath = os.path.join(local_dir, os.path.basename(blob))\n","        print(f\"Downloading {blob} to {local_filepath}...\")\n","        fs.get(blob, local_filepath)\n","\n","download_from_gcs(gcs_model_path, local_model_dir)\n","\n","print(\"Model files downloaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAHXS8bavfU8","executionInfo":{"status":"ok","timestamp":1742779976824,"user_tz":240,"elapsed":376501,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"96664a89-eb47-4178-fc72-436a160cf6a7"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading llm-test-bucket-2025/model_weights/config.json to deepseek_model_4b/config.json...\n","Downloading llm-test-bucket-2025/model_weights/generation_config.json to deepseek_model_4b/generation_config.json...\n","Downloading llm-test-bucket-2025/model_weights/model-00001-of-00002.safetensors to deepseek_model_4b/model-00001-of-00002.safetensors...\n","Downloading llm-test-bucket-2025/model_weights/model-00002-of-00002.safetensors to deepseek_model_4b/model-00002-of-00002.safetensors...\n","Downloading llm-test-bucket-2025/model_weights/model.safetensors.index.json to deepseek_model_4b/model.safetensors.index.json...\n","Downloading llm-test-bucket-2025/model_weights/special_tokens_map.json to deepseek_model_4b/special_tokens_map.json...\n","Downloading llm-test-bucket-2025/model_weights/tokenizer.json to deepseek_model_4b/tokenizer.json...\n","Downloading llm-test-bucket-2025/model_weights/tokenizer_config.json to deepseek_model_4b/tokenizer_config.json...\n","Model files downloaded successfully!\n"]}]},{"cell_type":"code","source":["# Define prompt\n","prompt = \"Explain the benefits of LLM-based AI applications.\"\n","\n","# Tokenize input\n","inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","# Generate output\n","with torch.no_grad():\n","    output = model.generate(**inputs, max_new_tokens=150)\n","\n","# Decode and print response\n","response = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(\"Response:\\n\", response)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsqBA3ZOwzMM","executionInfo":{"status":"ok","timestamp":1742780041444,"user_tz":240,"elapsed":7882,"user":{"displayName":"Salah Uddin","userId":"15536866033402565836"}},"outputId":"bf5585bc-933b-4696-ac28-98c178d4a0ea"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Response:\n"," Explain the benefits of LLM-based AI applications. What industries are most impacted by these tools?\n","Hmm, so I need to explain the benefits of LLM-based AI applications and the industries most affected by them. Let me start by recalling what LLM-based AI applications are. Large Language Models, like GPT-3 or 4, use massive datasets to generate text and perform tasks. They're powerful because they can understand and generate human-like text.\n","\n","First, the benefits. Well, these models are good at understanding and generating text, which is useful for many tasks. So, I can think of areas where natural language processing is important. Like writing assistance—so for writers, it can help generate ideas or improve drafts. Similarly, content creation tools, maybe for marketers or copywriters.\n","\n","Another\n"]}]}]}